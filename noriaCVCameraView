import SwiftUI
import AVFoundation
import Vision

struct CameraView: UIViewControllerRepresentable {
    func makeUIViewController(context: Context) -> CameraViewController {
        return CameraViewController()
    }

    func updateUIViewController(_ uiViewController: CameraViewController, context: Context) {}

    class CameraViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate {
        var captureSession: AVCaptureSession!
        var previewLayer: AVCaptureVideoPreviewLayer!
        let speechSynthesizer = AVSpeechSynthesizer() // 游닉 Agregar el sintetizador de voz
        var lastSpokenLabel: String? // Guarda el 칰ltimo objeto dicho en voz alta

        override func viewDidLoad() {
            super.viewDidLoad()
            setupCamera()
        }

        func setupCamera() {
            captureSession = AVCaptureSession()
            captureSession.sessionPreset = .high
            
            guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
                print("No se pudo acceder a la c치mara")
                return
            }

            do {
                let input = try AVCaptureDeviceInput(device: camera)
                if captureSession.canAddInput(input) {
                    captureSession.addInput(input)
                }
                
                let output = AVCaptureVideoDataOutput()
                output.setSampleBufferDelegate(self, queue: DispatchQueue(label: "videoQueue"))
                if captureSession.canAddOutput(output) {
                    captureSession.addOutput(output)
                }
                
                previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
                previewLayer.videoGravity = .resizeAspectFill
                previewLayer.frame = view.layer.bounds
                view.layer.addSublayer(previewLayer)

                DispatchQueue.global(qos: .background).async {
                    self.captureSession.startRunning()
                }
                
            } catch {
                print("Error al configurar la c치mara: \(error)")
            }
        }

        func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
            guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
            
            DispatchQueue.global(qos: .userInitiated).async {
                let observations = ObjectDetector.shared.detectObjects(pixelBuffer: pixelBuffer)
                DispatchQueue.main.async {
                    self.drawBoundingBoxes(for: observations)
                    self.announceDetectedObjects(observations)
                }
            }
        }

        /// 游댳 Funci칩n para dibujar cuadros y etiquetas en la pantalla
        func drawBoundingBoxes(for observations: [VNRecognizedObjectObservation]) {
            DispatchQueue.main.async {
                self.view.layer.sublayers?.removeSubrange(1...)
            }
            
            for observation in observations {
                let boundingBox = observation.boundingBox
                let label = observation.labels.first?.identifier ?? "Desconocido"
                let confidence = observation.labels.first?.confidence ?? 0.0
                
                let frame = CGRect(
                    x: boundingBox.origin.x * self.view.frame.width,
                    y: (1 - boundingBox.origin.y - boundingBox.height) * self.view.frame.height,
                    width: boundingBox.width * self.view.frame.width,
                    height: boundingBox.height * self.view.frame.height
                )

                // 游댳 Dibuja el rect치ngulo rojo
                let boxLayer = CALayer()
                boxLayer.frame = frame
                boxLayer.borderColor = UIColor.red.cgColor
                boxLayer.borderWidth = 2.0

                // 游댳 Dibuja la etiqueta con el nombre y confianza
                let textLayer = CATextLayer()
                textLayer.string = "\(label) \(Int(confidence * 100))%"
                textLayer.foregroundColor = UIColor.white.cgColor
                textLayer.fontSize = 14
                textLayer.frame = CGRect(x: frame.origin.x, y: frame.origin.y - 20, width: frame.width, height: 20)
                textLayer.backgroundColor = UIColor.black.withAlphaComponent(0.7).cgColor
                textLayer.alignmentMode = .center

                DispatchQueue.main.async {
                    self.view.layer.addSublayer(boxLayer)
                    self.view.layer.addSublayer(textLayer)
                }
            }
        }

        /// 游닉 **Nueva funci칩n para anunciar el objeto detectado**
        func announceDetectedObjects(_ observations: [VNRecognizedObjectObservation]) {
            guard let observation = observations.first else { return }
            let label = observation.labels.first?.identifier ?? "Desconocido"
            
            // Evita repetir la misma etiqueta si ya fue anunciada recientemente
            if label != lastSpokenLabel {
                let utterance = AVSpeechUtterance(string: "Veo un \(label)")
                
                // 游댳 Usar el idioma por defecto del sistema
                utterance.voice = AVSpeechSynthesisVoice(language: AVSpeechSynthesisVoice.currentLanguageCode())
                
                utterance.rate = 0.5 // Velocidad de la voz
                speechSynthesizer.speak(utterance)
                
                lastSpokenLabel = label
            }
        }
    }
}

